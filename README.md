# Data ingestion project #
---
## О проекте ##

Реализуем ETL pipline, который забирает данные об обращениях в полицию в Сан-Франциско ([link](https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-2018-to-Present/wg3w-h783)) и помещает их в базу данных.

Используемые технологии:

* Postgres - база данных;
* Python для написания скриптов;
* Airflow, так как данные на сайте периодически обновляются будем запускать скрипты по расписанию - раз в месяц;
* Docker - база данных и Airflow будут работать в контейнерах;
* Bash - в скрипте скачивания файла;

Пайплайн:

1. Скачиваем csv файл с данными и сохраняем локально.
2. Проверям корректность данных перед записью в базу.
3. Создаем таблицу в базе данных и записываем в нее данные из файла.

Для использования проекта нужно запустить файлы:

* ./docker-compose.yaml (запускает сетап airflow)
* ./de_project/docker-compose.yaml (поднимает базу данных Postgres).






